{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# link to metadata: https://www.kaggle.com/weil41/flights/data \n",
    "airlines2015 = pd.read_csv(\"airlines.csv\")\n",
    "airports2015 = pd.read_csv(\"airports.csv\")\n",
    "flights2015 = pd.read_csv(\"flights.csv\", dtype={\"ORIGIN_AIRPORT\":str, \"DESTINATION_AIRPORT\":str})\n",
    "flights2016 = pd.read_csv(\"2016_cleaned.csv\")\n",
    "flights2017 = pd.read_csv(\"current_flights.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out which flights are delayed\n",
    "# make a delayed variable\n",
    "cols = ['DAY_OF_WEEK', 'MONTH', 'DAY', 'AIRLINE', 'DISTANCE', 'SCHEDULED_DEPARTURE', 'SCHEDULED_TIME', 'DEPARTURE_DELAY']\n",
    "col_types = {'DAY_OF_WEEK': float, 'MONTH': float, 'DAY': float, 'AIRLINE': str, 'DISTANCE': float, 'SCHEDULED_DEPARTURE': float, 'SCHEDULED_TIME': float, 'DEPARTURE_DELAY': float}\n",
    "\n",
    "flights2015 = flights2015[cols]\n",
    "flights2016 = flights2016[cols]\n",
    "flights2017 = flights2017[cols]\n",
    "\n",
    "flights2015['DELAYED'] = 0.0\n",
    "flights2015.loc[flights2015['DEPARTURE_DELAY'] > 10, 'DELAYED'] = 1.0\n",
    "\n",
    "flights2016['DELAYED'] = 0\n",
    "flights2016.loc[flights2016['DEPARTURE_DELAY'] > 10, 'DELAYED'] = 1.0\n",
    "\n",
    "flights2017['DELAYED'] = 0.0\n",
    "flights2017.loc[flights2017['DEPARTURE_DELAY'] > 10, 'DELAYED'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing Datasets\n",
    "from sklearn.preprocessing import Imputer, LabelEncoder, OneHotEncoder\n",
    "\n",
    "#Preprocessing for 2015 data\n",
    "#Imputer 2015\n",
    "imputer = Imputer(missing_values ='NaN', strategy = 'mean', axis = 0)\n",
    "imputer = imputer.fit(flights2015.values[:,0:2])\n",
    "flights2015.iloc[:, 0:2] = imputer.transform(flights2015.values[:,0:2])\n",
    "\n",
    "#LabelEncoder 2015\n",
    "labelencoder_X = LabelEncoder()\n",
    "flights2015.iloc[:,0] = labelencoder_X.fit_transform(flights2015.values[:, 0])\n",
    "flights2015.iloc[:,1] = labelencoder_X.fit_transform(flights2015.values[:, 1])\n",
    "flights2015.iloc[:,2] = labelencoder_X.fit_transform(flights2015.values[:, 2])\n",
    "flights2015.iloc[:,3] = labelencoder_X.fit_transform(flights2015.values[:, 3])\n",
    "\n",
    "#OneHotEncoder 2015\n",
    "flights2015 = flights2015.astype(float)\n",
    "flights2015 = flights2015.values\n",
    "flights2015 = flights2015[~np.isnan(flights2015).any(axis=1)]\n",
    "categ = [cols.index(x) for x in ['DAY_OF_WEEK', 'MONTH', 'DAY', 'AIRLINE']]\n",
    "enc = OneHotEncoder(categorical_features = categ)\n",
    "flights2015 = enc.fit_transform(flights2015).toarray()\n",
    "\n",
    "# #Preprocessing for 2016 data\n",
    "# #Imputer 2016\n",
    "# imputer = Imputer(missing_values ='NaN', strategy = 'mean', axis = 0)\n",
    "# imputer = imputer.fit(flights2016.values[:,0:2])\n",
    "# flights2016.iloc[:, 0:2] = imputer.transform(flights2016.values[:,0:2])\n",
    "\n",
    "# #LabelEncoder 2016\n",
    "# labelencoder_X = LabelEncoder()\n",
    "# flights2016.iloc[:,3] = labelencoder_X.fit_transform(flights2016.values[:, 3])\n",
    "\n",
    "# #OneHotEncoder 2016\n",
    "# flights2016 = flights2016.astype(float)\n",
    "# flights2016 = flights2016.values\n",
    "# flights2016 = flights2016[~np.isnan(flights2016).any(axis=1)]\n",
    "# categ = [cols.index(x) for x in ['DAY_OF_WEEK', 'MONTH', 'DAY', 'AIRLINE']]\n",
    "# enc = OneHotEncoder(categorical_features = categ)\n",
    "# flights2016 = enc.fit_transform(flights2016).toarray()\n",
    "\n",
    "# #Preprocessing for 2017 data\n",
    "# #Imputer 2017\n",
    "# imputer = Imputer(missing_values ='NaN', strategy = 'mean', axis = 0)\n",
    "# imputer = imputer.fit(flights2017.values[:,0:2])\n",
    "# flights2017.iloc[:, 0:2] = imputer.transform(flights2017.values[:,0:2])\n",
    "\n",
    "# #LabelEncoder 2017\n",
    "# labelencoder_X = LabelEncoder()\n",
    "# flights2017.iloc[:,3] = labelencoder_X.fit_transform(flights2017.values[:, 3])\n",
    "\n",
    "# #OneHotEncoder 2017\n",
    "# flights2017 = flights2017.astype(float)\n",
    "# flights2017 = flights2017.values\n",
    "# flights2017 = flights2017[~np.isnan(flights2017).any(axis=1)]\n",
    "# categ = [cols.index(x) for x in ['DAY_OF_WEEK', 'MONTH', 'DAY', 'AIRLINE']]\n",
    "# enc = OneHotEncoder(categorical_features = categ)\n",
    "# flights2017 = enc.fit_transform(flights2015).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flights2015[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights2016.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights2017.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flights 2015 - Number of Observations ::  5732920\n",
      "Flights 2016 - Number of Observations ::  1829534\n",
      "Flights 2017 - Number of Observations ::  3\n",
      "train_x2015 size ::  (5732920, 58)\n",
      "train_y2015 size ::  (5732920,)\n",
      "test_x2016 size ::  (1829534, 58)\n",
      "test_y2016 size ::  (1829534,)\n",
      "training regression model\n",
      "regression model trained\n",
      "train accuracy completed\n",
      "testing accuracy completed\n",
      "Train Accuracy ::  0.97986226914\n",
      "Test Accuracy ::  0.787166021511\n"
     ]
    }
   ],
   "source": [
    "# Required Python Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdb\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "def dataset_headers(dataset):\n",
    "    \"\"\"\n",
    "    To get the dataset header names\n",
    "    :param dataset: loaded dataset into pandas DataFrame\n",
    "    :return: list of header names\n",
    "    \"\"\"\n",
    "    return list(dataset.columns.values)\n",
    "\n",
    "\n",
    "def unique_observations(dataset, header, method=1):\n",
    "    \"\"\"\n",
    "    To get unique observations in the loaded pandas DataFrame column\n",
    "    :param dataset:\n",
    "    :param header:\n",
    "    :param method: Method to perform the unique (default method=1 for pandas and method=0 for numpy )\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if method == 0:\n",
    "            # With Numpy\n",
    "            observations = np.unique(dataset[[header]])\n",
    "        elif method == 1:\n",
    "            # With Pandas\n",
    "            observations = pd.unique(dataset[header].values.ravel())\n",
    "        else:\n",
    "            observations = None\n",
    "            print(\"Wrong method type, Use 1 for pandas and 0 for numpy\")\n",
    "    except Exception as e:\n",
    "        observations = None\n",
    "        print(\"Error: {error_msg} /n Please check the inputs once..!\".format(error_msg=e.message))\n",
    "    return observations\n",
    "\n",
    "\n",
    "def feature_target_frequency_relation(dataset, f_t_headers):\n",
    "\n",
    "    \"\"\"\n",
    "    To get the frequency relation between targets and the unique feature observations\n",
    "    :param dataset:\n",
    "    :param f_t_headers: feature and target header\n",
    "    :return: feature unique observations dictionary of frequency count dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    feature_unique_observations = unique_observations(dataset, f_t_headers[0])\n",
    "    unique_targets = unique_observations(dataset, f_t_headers[1])\n",
    "\n",
    "    frequencies = {}\n",
    "    for feature in feature_unique_observations:\n",
    "        frequencies[feature] = {unique_targets[0]: len(\n",
    "            dataset[(dataset[f_t_headers[0]] == feature) & (dataset[f_t_headers[1]] == unique_targets[0])]),\n",
    "            unique_targets[1]: len(\n",
    "                dataset[(dataset[f_t_headers[0]] == feature) & (dataset[f_t_headers[1]] == unique_targets[1])])}\n",
    "    return frequencies\n",
    "\n",
    "\n",
    "def feature_target_histogram(feature_target_frequencies, feature_header):\n",
    "    \"\"\"\n",
    "    :param feature_target_frequencies:\n",
    "    :param feature_header:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    keys = feature_target_frequencies.keys()\n",
    "    y0 = [feature_target_frequencies[key][0] for key in keys]\n",
    "    y1 = [feature_target_frequencies[key][1] for key in keys]\n",
    "\n",
    "    trace1 = go.Bar(\n",
    "        x=keys,\n",
    "        y=y0,\n",
    "        name='No Delay'\n",
    "    )\n",
    "    trace2 = go.Bar(\n",
    "        x=keys,\n",
    "        y=y1,\n",
    "        name='Delay'\n",
    "    )\n",
    "    data = [trace1, trace2]\n",
    "    layout = go.Layout(\n",
    "        barmode='group',\n",
    "        title='Feature :: ' + feature_header + ' No Delay Vs Delay  Frequency',\n",
    "        xaxis=dict(title=\"Feature :: \" + feature_header + \" classes\"),\n",
    "        yaxis=dict(title=\"Delay Frequency\")\n",
    "    )\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    plot_url = py.plot(fig, filename=feature_header + ' - Target - Histogram')\n",
    "    py.image.save_as(fig, filename=feature_header + '_Target_Histogram.png')\n",
    "\n",
    "\n",
    "def train_logistic_regression(train_x, train_y):\n",
    "    \"\"\"\n",
    "    Training logistic regression model with train dataset features(train_x) and target(train_y)\n",
    "    :param train_x:\n",
    "    :param train_y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    logistic_regression_model = LogisticRegression()\n",
    "    logistic_regression_model.fit(train_x, train_y)\n",
    "    return logistic_regression_model\n",
    "\n",
    "\n",
    "def model_accuracy(trained_model, features, targets):\n",
    "    \"\"\"\n",
    "    Get the accuracy score of the model\n",
    "    :param trained_model:\n",
    "    :param features:\n",
    "    :param targets:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    accuracy_score = trained_model.score(features, targets)\n",
    "    return accuracy_score\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Logistic Regression classifier main\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Load the datasets for training and testing the logistic regression classifier\n",
    "    dataset = flights2015\n",
    "    dataset2 = flights2016\n",
    "    dataset3 = flights2017\n",
    "    \n",
    "    print(\"Flights 2015 - Number of Observations :: \", len(dataset))\n",
    "    print(\"Flights 2016 - Number of Observations :: \", len(dataset2))\n",
    "    print(\"Flights 2017 - Number of Observations :: \", len(dataset3))\n",
    "\n",
    "    training_features = ['MONTH', 'DAY', 'DAY_OF_WEEK', 'DISTANCE', 'SCHEDULED_DEPARTURE', 'AIRLINE_NUMBER', 'SCHEDULED_TIME']\n",
    "    target = 'DELAYED'\n",
    "    \n",
    "    train_x2015 = dataset[:, :58]\n",
    "    train_y2015 = dataset[:, 58]\n",
    "    \n",
    "    print(\"train_x2015 size :: \", train_x2015.shape)\n",
    "    print(\"train_y2015 size :: \", train_y2015.shape)\n",
    "    \n",
    "    test_x2016 = dataset2[:, :58]\n",
    "    test_y2016 = dataset2[:, 58]\n",
    "    \n",
    "    print(\"test_x2016 size :: \", test_x2016.shape)\n",
    "    print(\"test_y2016 size :: \", test_y2016.shape)\n",
    "    \n",
    "    #test_x2017 = dataset3[:, :58]\n",
    "    #test_y2017 = dataset3[:, 58]\n",
    "    \n",
    "    #print(\"test_x2017 size :: \", test_x2017.shape)\n",
    "    #print(\"test_y2017 size :: \", test_y2017.shape)  \n",
    "\n",
    "    # Training Logistic regression model\n",
    "    print(\"training regression model\")\n",
    "    trained_logistic_regression_model = train_logistic_regression(train_x2015, train_y2015)\n",
    "    print(\"regression model trained\")\n",
    "\n",
    "    train_accuracy = model_accuracy(trained_logistic_regression_model, train_x2015, train_y2015)\n",
    "    print(\"train accuracy completed\")\n",
    "\n",
    "    # Testing the logistic regression model\n",
    "    test_accuracy = model_accuracy(trained_logistic_regression_model, test_x2016, test_y2016)\n",
    "    print(\"testing accuracy completed\")\n",
    "\n",
    "    print(\"Train Accuracy :: \", train_accuracy)\n",
    "    print(\"Test Accuracy :: \", test_accuracy)\n",
    "    \n",
    "    #print(trained_logistic_regression_model.predict(flights2017[training_features]))\n",
    "    #print(trained_logistic_regression_model.predict_proba(flights2017[training_features]))\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
